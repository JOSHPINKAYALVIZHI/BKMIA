{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJsv5lwpEkXl2rjkoUOM30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JOSHPINKAYALVIZHI/BKMIA/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uIy3AYzxGMzo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=(128,128)\n",
        "batch=4"
      ],
      "metadata": {
        "id": "yZ_NCVJNH48-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen=ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "train=gen.flow_from_directory('dataset',target_size=img_size,batch_size=batch,class_mode='binary',subset='training')\n",
        "val=gen.flow_from_directory('dataset',target_size=img_size,batch_size=batch,class_mode='binary',subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "argGZOCGIQRs",
        "outputId": "2738bd3d-6151-4cef-fea5-4a414c81553b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8 images belonging to 3 classes.\n",
            "Found 2 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(128,128,3)),\n",
        "    tf.keras.layers.Conv2D(32,3,activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Conv2D(64,3,activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "])\n",
        ""
      ],
      "metadata": {
        "id": "wBAZKfjFJORG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(train,validation_data=val,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8k75Co6LrcB",
        "outputId": "77304e68-5d3b-48e1-d195-2bfbe8b15925"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - accuracy: 0.3333 - loss: -3.4860 - val_accuracy: 0.5000 - val_loss: -27.2951\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5000 - loss: -33.6210 - val_accuracy: 0.5000 - val_loss: -74.2444\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5000 - loss: -82.7163 - val_accuracy: 0.5000 - val_loss: -149.1510\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5000 - loss: -166.7153 - val_accuracy: 0.5000 - val_loss: -261.7272\n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5833 - loss: -250.2052 - val_accuracy: 0.5000 - val_loss: -415.1930\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5000 - loss: -447.0615 - val_accuracy: 0.5000 - val_loss: -627.9100\n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5000 - loss: -677.5037 - val_accuracy: 0.5000 - val_loss: -923.2507\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.4167 - loss: -1089.6165 - val_accuracy: 0.5000 - val_loss: -1314.5079\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5833 - loss: -1260.9254 - val_accuracy: 0.5000 - val_loss: -1823.3743\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.4167 - loss: -2232.3918 - val_accuracy: 0.5000 - val_loss: -2474.1917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a956d1df090>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img_path='/content/Untitled Folder/Screenshot 2025-05-05 115309.png'\n",
        "img=image.load_img(img_path,target_size=img_size)\n",
        "img_array=image.img_to_array(img)\n",
        "img_batch=numpy.expand_dims(img_array,axis=0)\n",
        "prediction=model.predict(img_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSpnkyrKL6MM",
        "outputId": "017f0ef3-41ec-472f-fbec-ef898de5b197"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsKMOXfmO2OL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}